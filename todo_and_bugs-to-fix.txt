
** BUGS TO FIX:


** NEAR-TERM FUTURE TODO:

[-] Implement Kahan summation in ModelObject::FindTotalFluxes
	-- http://stackoverflow.com/questions/18013345/openmp-parallel-for-reduction-delivers-wrong-results
	[x] Compute some current flux outputs (e.g., including correct total flux for Exponential)
	[x] Implement Kahan summation
	[x] Compare results with/without Kahan summation
	
	RESUT: for case of simple Gaussian model, Kahan summation took 2--3 times as long
	and produced *no* difference in calculated flux (at 10^-5 level), even for a
	very extended Gaussian.


[X] Test for possible memory-allocation failures
	[x] Reading in large images -- effectively already caught by cfitsio
	[x] Allocating memory for model images
	[x] Allocating memory for internally-generated error image
	[x] Allocating memory for weight image
	[x] Allocating FFTW arrays in Convolver
	[x] Test using makeimage and very large --nrows,--ncols ?


[] Convert total-pixel-number integer variables to long
	model_object.h: nModelVals, nDataVals, nValidDataVals, nOversampledModelVals
	model_object.cpp: 
		ModelObject::AddErrorVector( int nDataValues
		ModelObject::AddMaskVector( int nDataValues
		ModelObject::AddPSFVector( int nPixels_psf
		ModelObject::AddOversampledPSFVector( int nPixels
		int ModelObject::FinalSetupForFitting( ) -- nNonFinitePixels, nNonFiniteErrorPixels
		Assorted for-loop index variables when looping over pixels
		bootstrap indices
			-- also make sure RNG can return long values

	convolver.h: nPixels_image, nPixels_psf, nPixels_padded; nPixels_padded_complex
		QUESTION: Can FFTW *handle* longs for pixel numbers?
	convolver.cpp: Convolver::ShiftAndWrapPSF( ) -- pos_in_psf, pos_in_dest;
	oversampled_region.h: nModelVals
	oversampled_region.cpp: ---
	image_io.h: 
	image_io.cpp: 
		ReadImageAsVector -- nPixelsTot
	makeimage_main.cpp: 
	imfit_main.cpp: 


[..] Add "const" specifiers to input parameters of functions, as appropriate
	Done through: convolver


[] Possible improved error reporting
	[] When negative pixel values are encountered during vetting of input data image,
	mention possibility of missing sky parameter
	

[] Modify handling of oversampled PSF to catch case where user wants entire
image oversampled
	-- e.g., if total number of pixels in main + oversampled region (model images,
	including edge-padding for PSF) > number of pixels in hypothetical oversampling
	of entire image ==> switch to oversampling of entire image

	-- need to test this to make sure time spent isn't wrongly estimated (e.g.,
	actual time with oversampling includes FFT + downsampling)
	
	-- add option for user to specify this directly?
	e.g. "--overpsf_region all"


[] Combine code for generating output header 
	Currently: lines 329--335 and also 369--375 of print_results.cpp
	-- generate in main() as list of strings?
	-- would allow us to remove "string& programName, int argc, char *argv[]" from
	interface of SaveParams() and SaveParams2()


[..] Reorganize directory structure:
	[x]src/core
	[x]src/solvers
	[x]src/function_objects
	src/function_objects_extra -- for specialized, non-public stuff (n4762 funcs, experimental stuff, etc.)
	[x]src/function_objects_1d
	[x]src/profilefit -- for all the 1D stuff (except func1d_*)
	src/utilities ?
	src/extra ? -- for timing_main.cpp
	src/model_object ? -- for model_object convolver oversampled_region downsample
		[but note that Convolver is used by psfconvolve_main.cpp
	[x]tests/ -- regression tests, etc.
	[x]unit_tests/
	[x]docs/ -- where Doxygen input files go
		html -- created by Doxygen
		latex -- created by Doxygen
	
	[] Possibly create SConstript files for subdirectories -- see 
	http://stackoverflow.com/questions/8810418/scons-setup-for-hierarchical-source-but-single-target
	[or maybe not, since that's getting into "recursive Makefile considered harmful"
	territory, even if SCons isn't necessarily afflicted with the same problems]


[] Oversampling of multiple sub-regions (possibly with their own oversampled PSFs)
	-- multiple sub-regions, all with same PSF
	-- multiple sub-regions, each with its own PSF
	-- probably simpler to require that each sub-region have its own PSF; use must
	repeatedly specify the same PSF file if they want all sub-regions to share a PSF
	
	[] Code up user interface (vector of sub-region and PSF specifications in main)
	
	[] Code up array of sub-region convolutions in ModelObject
		[] New data members: nSubregions
		[] Start with 1-element array (i.e., have all the looping, etc., but just one sub-region)
		[] Add in code to set up multiple sub-regions


[] Refactor print_results.cpp to be simpler and less mangled-from-mpfit


[] Look into possible use of FFTW++ library for convolution
	-- C++ wrapper around FFTW, with added optimization for "implicit zero-padding"
	of convolutions

[] Optional convolution with charge-diffusion kernel?


[] Annotations to describe function parameters
	-- optional text strings in a FunctionObject class which provide a short, one-line
	description/reminder of what the parameter is (and maybe its units?)
	-- printed on same line as parameter name, with "#" in between
	-- possibly alternate command-line flag to specify this instead of the
	current, "bare-bones" version

[] User annotations for functions in config file
	-- i.e., allow user to add names to individual functions, e.g.
	FUNCTION Sersic   # NGC 100: bulge
	-- these would be stored and written to output files


[] Add option for MCMC
	-- Start with Metropolis-Hastings, just to make sure we get the overall
	machinery working
		-- Then try DE-MCMC (ter Braak; 
			-- C++ code for "DREAM" here: http://people.sc.fsu.edu/~jburkardt/cpp_src/dream/dream.html
			(this is really C code with some minmimal C++ idioms, like std::string)
	-- Option to use config file for initial conditions
	-- Run L-M first to generate initial conditions and parameter sigmas
		-- alternate: run L-M separately, then use results as initial conditions
		with different/expanded parameter limits just for MCMC
	-- possibly user-supplied scale factor: multiply L-M sigmas by this
	to get Gaussian sigmas for proposal/jump functions
	-- "prior probability" is flat, with possible parameter-limit cutoffs
	-- may need to enforce universal parameter-limit cutoffs (don't want to sample
	from unbounded distributions; problems with PA sampling; may need to
	enforce 0--1 bounds for ellipticity, etc. even if user didn't originally
	worry about them for fitting process.
	-- "posterior-probability" function is our usual chi^2 or PMLR, plus
	parameter-limit cutoffs
	

[] Compiling parts of program(s) into a library, which is then linked when
compiling imfit and makeimage (and other things, like timing). Idea is to set
things up so it's easier for other people to use "libimfit" without the
specific input/output functionality/limitations of imfit/makeimage.



** MINOR BUGS TO FIX/IMPROVEMENTS TO MAKE:



* BUGS FIXED

[X] Convolution of an image with substantial region of negative pixels produces
weird ringing and positive pixels in negative region.
	Reported by Semyeong Oh
	-- tests using astropy.convolution.convolve() and astropy.convolution.convolve_fft()
	show apparently correct results
	-- see if this also happens with 1-D convolution?
	?? Is output the absolute value of what it should be?
		-- compare with astropy.convolution output
			[]1. Compare astropy.convolution output on all-positive image (how much
			does our convolution differ from theirs?)
			[]2. Compare astropy.convolution output on partially-negative image
	-- This turns out to have been a longstanding bug due to the fact that I ahd
	(for some mysterious reason) taken the absolute value of the inverse transform
	at the end of the convolution. This had no effect when all pixels were >= 0,
	but was wrong for negative pixels... Accidentally fixed in version 1.3 when
	I changed how the transform was computed.


[X] --quiet option with Nelder-Mead simplex (--nm) is not truly quiet (some of N-M
simplex output is suppressed, but "iteration XXX" is still printed)
	-- OK, this is a difference between the current version of NLopt library ints
	dynamic form (what we normally use) and the static-linking one

[X] Compiling with our SCons option --no-nlopt fails to catch references to NLopt
function NMSimplexFit in bootstrap_errors.cpp
	Reported by Guillermo Barro
	-- FIX: add preprocessor directives to comment out all references to NLopt stuff

[X] Doing bootstrap resampling when the input config file contains the best-fitting
solution for the model + image results in mysteriously non-existent boostrap
error estimates:
E.g., [with version 1.3b; seen by Semyeong Oh in an earlier version]
$ ./imfit tests/ic3478rss_64x64.fits --config tests/imfit_config_ic3478_64x64.dat --gain=4.725 --readnoise=4.3 --sky=130.1 --bootstrap 100
	==> OK output
$ ./imfit tests/ic3478rss_64x64.fits --config bestfit_parameters_imfit.dat --gain=4.725 --readnoise=4.3 --sky=130.1 --bootstrap 100
	==> yieds:
Best-fit		 Bootstrap      [68% conf.int., half-width]; (mean +/- standard deviation)
X0 = 32.9439     [fixed parameter]
Y0 = 34.0933     [fixed parameter]
PA = 18.2613     [fixed parameter]
ell = 0.235989     [fixed parameter]
n = 2.40028     [fixed parameter]
I_e = 20.0094     [fixed parameter]
r_e = 60.7611     [fixed parameter]

f1 = '/Users/erwin/coding/imfit/bstest1.dat'
df1 = du.ReadCompositeTableFromText(open(f1).readlines(),dataFrame=True, columnRow=14)
f2 = '/Users/erwin/coding/imfit/bstest2.dat'
df2 = du.ReadCompositeTableFromText(open(f2).readlines(),dataFrame=True, columnRow=14)

astrostat.genstats(df1.X0_1)
astrostat.genstats(df2.X0_1)
astrostat.genstats(df1.Y0_1)
astrostat.genstats(df2.Y0_1)
astrostat.genstats(df1.n_1)
astrostat.genstats(df2.n_1)

OK, bootstrap output from 2nd case (starting with best-fit values) seems similar to
first case (starting from original guesses), so *that* part works...

OK, here is the problem:
	1. In BootstrapErrors(), we check for *fixed* parameters with this:
    if ((paramLimitsExist) && (parameterLimits[i].fixed == 0)) {
	BUT: if the config file had no limits at all (as is always true for an output
	best-fit parameters file), then paramLimitsExist = false
	
	Confirmed by removing all the limits from the regular param file
		==> produces the same "[fixed parameter]" output...
	
	[X] SOLUTION: Remove parameterLimitsExist test when determining whether to
	print conf. intervals



* IMPROVEMENTS APPLIED

[X] Implement Kahan summation in PSF normalization
	Convolver::DoFullSetup

[X] New class encapsulating return metadata from minimizers (like mp_results, but
for all minimizers)

[X] Update memory estimation to account for smaller FFT-related arrays

[x] Update memory estimation to account for possible oversampled PSF use

[X] Add one or two oversampled-PSF tests to do_imfit_tests (and do_makeimage_tests)
	do_makeimage_tests -- ensure that we recreate reference image

[X] Option to output default/simple configuration file (and then quite)
	-- for imfit, this could include e.g. GAIN = 1 as well as single function
	-- for makeimage, this could include NROWS and NCOLS as well as single function

[X] FOR V1.3: Tweak output of best-fit parameters for mult-function-block case
	-- currently, additional function blocks are appended directly; would be
	nicer to have a blank line before each new "X0 ..." line
	
	
[X] FOR V1.3: King model FunctionObject
	-- function_objects/func_king.h/cpp : in progress
	-- need to set up some profile-computation tests (e.g., compare 1-D slices
	through output image with 1-D profiles generated by ...?)
		[x] Write Python code to implement function; test by generating plot
		with same ranges as Fig.10 of Peng+2010 and comparing (overlay in Illustrator?)
		[x] Generate plot with all profiles
		[x] Compare plot with Fig.10 of Peng+2010 in Illustrator
	[x]-- check that we get I= 0 for r > r_t; possibly introduce shortcut in code
	to just return 0 in that case.
		[x] Generate images (with no subsampling) and compare profiles with
		output of Python code
		[x] Set up unit tests
	[x] Add variant model where concentration (r_t/r_c) is adjustable parameter
	[x] Add notes to documentation for Modified King function


[x] FOR V1.3: Convert handling of user-supplied "weight" map ("--errors-are-weights")
	so that the user can assume "weight = inverse variance" (rather than 
	"weight = inverse simga", which is how it's actually implemented at present)
		-- set up comparison tests
		-- Need to modify ModelObject::GetWeightImageVector [used in imfit_main.cpp]
		
		[x]0. Set up unit tests
		[x]1. Modify ModelObject::GetWeightImageVector to output 1/sigma^2 weights
		[x]2. Modify ModelObject::AddErrorVector to convert "weight" input properly
		[x]3. Edit imfit_howto.tex to reflect reality of weights
		[x]4. modify do_imfit_tests to incorporate weight-map checks
				[] Input maps produce approx. same fits as internally-generated maps
				[] Output weight maps are approx. correct
				[] Input an error map and output it; check


[X] Makeimage should quit when encountering unknown command-line parameter (like imift)


[X] Solver summary info in header of bestfit_parameters output should include
	subtype of chi^2 (i.e., "(data-based)", "(model-based)", "(user-supplied noise map"),
	or something like that)


[X] Handle multi-extension FITS images
	-- at least to the point of recognizing them and complaining clearly
		
	[] When reading in a FITS file (data, mask, PSF, etc.), check to see if
	it's multi-extension
		[X] Generate error if primary HDU is *not* a 2D image
	
	[] PROBLEM: how to handle user-suppled "....fits[n]" filename?
		Need to check that image *had* at least n HDUs
		Need to explicitly check whether HDU n is an image
	
	WHERE WE ARE, WHAT TO DO NEXT:
		1. ./imfit tests/test_multiextension_hdu1empty.fits --config tests/imfit_config_ic3478_64x64b.dat
		FAILS because, inside ReadImageAsVector, CheckImage returns 2 [we think] for
		valid HDU number, but ReadImageAsVector only checks to see if value is > 0,
		and then goes ahead and reads the first HDU!
			-- ReadImageAsVector needs to check 
			-- How should ReadImageAsVector and CheckImage handle user-specified
			"[n]" HDU numbers?
		2. We need to figure out how cfitsio numbers the HDUs (is the first one always
		"[1]"? what happens if user gives "[0]"			
			OK: the answer is: "The HDU may be specified either by
			absolute position number, starting with 0 for the primary
			array, or by reference to the HDU name, and optionally, the
			version number and the HDU type of the desired extension."
			
			BUT: the documentation for fits_movabs_hdu says: "The first
			routine moves to a specified absolute HDU number (starting
			with 1 for the primary array) in the FITS file,"
			
			SO: User-specified "[n]" numbering is 0-based, but internal
			numbering is 1-based!


*[X] Check input noise map (if supplied) for NaN values and add those pixels
to mask.
			1. Go through error and mask image simultaneously, ID bad error pixels
			and add to mask
			
			
	[X] Set up example noise-map image with NaN values for testing
	[X] Apply change to:
		ModelObject::FinalSetupForFitting( )
		[after "Identify currently unmasked data pixels which have non-finite values" step]
	[X] Test change

